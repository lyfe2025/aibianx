#!/bin/bash

# AIå˜ç°ä¹‹è·¯ - å¼€å‘ç¯å¢ƒå¿«é€Ÿå¯åŠ¨è„šæœ¬
# ç”¨äºåŒæ—¶å¯åŠ¨Strapiåç«¯å’ŒNext.jså‰ç«¯

echo "ğŸš€ AIå˜ç°ä¹‹è·¯ - å¼€å‘ç¯å¢ƒå¯åŠ¨ä¸­..."
echo "========================================="

# åˆ›å»ºæ—¥å¿—ç›®å½•
mkdir -p logs

# è·å–é¡¹ç›®æ ¹ç›®å½•
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/../.." && pwd)"

# åŠ è½½ç»Ÿä¸€ç¯å¢ƒé…ç½®ï¼ˆä¼˜å…ˆï¼‰
source "${PROJECT_ROOT}/deployment/configure-unified-env.sh"

# æ£€æŸ¥Node.jsç‰ˆæœ¬
if ! command -v node &> /dev/null; then
    echo "âŒ Node.js æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£… Node.js 18+"
    exit 1
fi

echo "âœ… Node.js ç‰ˆæœ¬: $(node --version)"

# åŠ è½½å…¼å®¹çš„æ—§é…ç½®ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
source "$(dirname "$0")/../tools/load-config.sh"
source "$(dirname "$0")/../tools/load-env.sh"
load_config

# åŠ è½½åç«¯ç¯å¢ƒå˜é‡ï¼ˆä¿®å¤æ•°æ®åº“ä¿¡æ¯æ˜¾ç¤ºé—®é¢˜ï¼‰
if ! load_backend_env; then
    echo "âŒ åŠ è½½åç«¯ç¯å¢ƒå˜é‡å¤±è´¥"
    exit 1
fi

# æ˜¾ç¤ºæ•°æ®åº“é…ç½®
echo "ğŸ—„ï¸ æ•°æ®åº“é…ç½®:"
echo "   ä¸»æœº: $DATABASE_HOST:$DATABASE_PORT"

# é…ç½®å¼€å‘ç¯å¢ƒå˜é‡ï¼ˆæ¸…ç†APIå¯†é’¥é…ç½®ï¼‰
configure_dev_env_variables() {
    # ğŸ”§ æ¸…ç†å¼€å‘ç¯å¢ƒçš„APIå¯†é’¥é…ç½®ï¼ˆå¼€å‘æ¨¡å¼æ— éœ€APIå¯†é’¥ï¼‰
    if [ -f "backend/.env" ]; then
        # æ¸…ç†åç«¯APIå¯†é’¥é…ç½®
        if grep -q "^MEILISEARCH_API_KEY=" backend/.env; then
            sed -i.bak "s/^MEILISEARCH_API_KEY=.*/MEILISEARCH_API_KEY=/" backend/.env
            echo "   âœ… å·²æ¸…ç†åç«¯ MEILISEARCH_API_KEY (å¼€å‘æ¨¡å¼æ— éœ€å¯†é’¥)"
        fi
        
        # ç¡®ä¿åç«¯æœç´¢é…ç½®æ­£ç¡® (ä½¿ç”¨åˆ†ç¦»é…ç½®æ ¼å¼)
        local backend_updated=false
        if grep -q "^MEILISEARCH_DOMAIN=" backend/.env; then
            sed -i.bak "s/^MEILISEARCH_DOMAIN=.*/MEILISEARCH_DOMAIN=localhost/" backend/.env
            backend_updated=true
        fi
        if grep -q "^MEILISEARCH_PORT=" backend/.env; then
            sed -i.bak "s/^MEILISEARCH_PORT=.*/MEILISEARCH_PORT=7700/" backend/.env
            backend_updated=true
        fi
        if grep -q "^MEILISEARCH_PROTOCOL=" backend/.env; then
            sed -i.bak "s/^MEILISEARCH_PROTOCOL=.*/MEILISEARCH_PROTOCOL=http/" backend/.env
            backend_updated=true
        fi
        
        if [ "$backend_updated" = true ]; then
            echo "   âœ… å·²é…ç½®åç«¯æœç´¢URL (localhost:7700)"
        fi
    fi
    
    if [ -f "frontend/.env.local" ]; then
        # æ¸…ç†å‰ç«¯APIå¯†é’¥é…ç½®
        if grep -q "^NEXT_PUBLIC_SEARCH_API_KEY=" frontend/.env.local; then
            sed -i.bak "s/^NEXT_PUBLIC_SEARCH_API_KEY=.*/NEXT_PUBLIC_SEARCH_API_KEY=/" frontend/.env.local
            echo "   âœ… å·²æ¸…ç†å‰ç«¯ NEXT_PUBLIC_SEARCH_API_KEY (å¼€å‘æ¨¡å¼æ— éœ€å¯†é’¥)"
        fi
        
        # ç¡®ä¿å‰ç«¯æœç´¢URLé…ç½®æ­£ç¡®ï¼ˆç¡®ä¿åè®®ã€åŸŸåã€ç«¯å£åˆ†ç¦»é…ç½®ï¼‰
        local need_backup=false
        if grep -q "^NEXT_PUBLIC_SEARCH_DOMAIN=" frontend/.env.local; then
            sed -i.bak "s/^NEXT_PUBLIC_SEARCH_DOMAIN=.*/NEXT_PUBLIC_SEARCH_DOMAIN=localhost/" frontend/.env.local
            need_backup=true
        fi
        if grep -q "^NEXT_PUBLIC_SEARCH_PORT=" frontend/.env.local; then
            sed -i.bak "s/^NEXT_PUBLIC_SEARCH_PORT=.*/NEXT_PUBLIC_SEARCH_PORT=7700/" frontend/.env.local
            need_backup=true
        fi
        if grep -q "^NEXT_PUBLIC_SEARCH_PROTOCOL=" frontend/.env.local; then
            sed -i.bak "s/^NEXT_PUBLIC_SEARCH_PROTOCOL=.*/NEXT_PUBLIC_SEARCH_PROTOCOL=http/" frontend/.env.local
            need_backup=true
        fi
        
        if [ "$need_backup" = true ]; then
            echo "   âœ… å·²é…ç½®å‰ç«¯æœç´¢URL (localhost:7700)"
        fi
    fi
}

# è‡ªåŠ¨éƒ¨ç½²MeiliSearchæœç´¢å¼•æ“
deploy_meilisearch() {
    echo ""
    echo "ğŸ” æ£€æŸ¥MeiliSearchæœç´¢å¼•æ“..."
    
    # æ£€æŸ¥MeiliSearchå®¹å™¨æ˜¯å¦å·²å­˜åœ¨
    if docker ps -a --format "table {{.Names}}" | grep -q "^meilisearch$"; then
        # æ£€æŸ¥æ˜¯å¦æ­£åœ¨è¿è¡Œ
        if docker ps --format "table {{.Names}}" | grep -q "^meilisearch$"; then
            echo "âœ… MeiliSearchå·²è¿è¡Œ"
            echo "   ğŸ“ é…ç½®å¼€å‘ç¯å¢ƒå˜é‡..."
            configure_dev_env_variables
            return 0
        else
            echo "ğŸ”„ å¯åŠ¨ç°æœ‰MeiliSearchå®¹å™¨..."
            docker start meilisearch > /dev/null 2>&1
            if [ $? -eq 0 ]; then
                echo "âœ… MeiliSearchå¯åŠ¨æˆåŠŸ"
                echo "   ğŸ“ é…ç½®å¼€å‘ç¯å¢ƒå˜é‡..."
                configure_dev_env_variables
                return 0
            fi
        fi
    fi
    
    echo "ğŸš€ è‡ªåŠ¨éƒ¨ç½²MeiliSearch (å¼€å‘ç¯å¢ƒæ¨¡å¼)..."
    
    # ç›´æ¥éƒ¨ç½²å¼€å‘ç¯å¢ƒï¼Œæ— éœ€äº¤äº’
    echo "   ğŸ”§ åœæ­¢ç°æœ‰MeiliSearchå®¹å™¨..."
    docker stop meilisearch 2>/dev/null && echo "   âœ… å·²åœæ­¢ç°æœ‰å®¹å™¨" || echo "   â„¹ï¸  æ²¡æœ‰è¿è¡Œä¸­çš„å®¹å™¨"
    docker rm meilisearch 2>/dev/null && echo "   âœ… å·²åˆ é™¤ç°æœ‰å®¹å™¨" || echo "   â„¹ï¸  æ²¡æœ‰éœ€è¦åˆ é™¤çš„å®¹å™¨"
    
    echo "   ğŸ“¦ éƒ¨ç½²å¼€å‘ç¯å¢ƒ..."
    docker run -d \
        --name meilisearch \
        -p 7700:7700 \
        -e MEILI_ENV=development \
        -v meilisearch_data:/meili_data \
        --restart unless-stopped \
        getmeili/meilisearch:latest > /dev/null 2>&1
    
    if [ $? -eq 0 ]; then
        # ç­‰å¾…å®¹å™¨å¯åŠ¨
        local count=0
        while [ $count -lt 15 ]; do
            if docker ps --format "table {{.Names}}" | grep -q "^meilisearch$"; then
                echo "âœ… MeiliSearchéƒ¨ç½²æˆåŠŸ"
                echo "   ğŸŒ Webç®¡ç†ç•Œé¢: ${MEILISEARCH_URL}"
                echo "   ğŸ”“ å¼€å‘æ¨¡å¼: æ— éœ€APIå¯†é’¥"
                
                # ğŸ”§ è‡ªåŠ¨é…ç½®å¼€å‘ç¯å¢ƒå˜é‡ï¼ˆæ¸…ç†APIå¯†é’¥ï¼‰
                echo "   ğŸ“ é…ç½®å¼€å‘ç¯å¢ƒå˜é‡..."
                configure_dev_env_variables
                
                return 0
            fi
            sleep 1
            count=$((count + 1))
        done
        echo "âš ï¸  MeiliSearchå®¹å™¨å¯åŠ¨è¾ƒæ…¢ï¼Œè¯·ç¨åæ£€æŸ¥"
    else
        echo "âŒ MeiliSearchéƒ¨ç½²å¤±è´¥ï¼Œè¯·æ£€æŸ¥DockerçŠ¶æ€"
    fi
}

# è‡ªåŠ¨éƒ¨ç½²BillionMailé‚®ä»¶ç³»ç»Ÿ
deploy_billionmail() {
    echo ""
    echo "ğŸ“§ æ£€æŸ¥BillionMailé‚®ä»¶ç³»ç»Ÿ..."
    
    # æ£€æŸ¥BillionMailå®¹å™¨æ˜¯å¦å·²å­˜åœ¨
    if docker ps -a --format "table {{.Names}}" | grep -q "^aibianx-billionmail-core$"; then
        # æ£€æŸ¥æ˜¯å¦æ­£åœ¨è¿è¡Œ
        if docker ps --format "table {{.Names}}" | grep -q "^aibianx-billionmail-core$"; then
            echo "âœ… BillionMailå·²è¿è¡Œ"
            echo "   ğŸŒ ç®¡ç†ç•Œé¢: ${BILLIONMAIL_WEB}"
            return 0
        else
            echo "ğŸ”„ å¯åŠ¨ç°æœ‰BillionMailå®¹å™¨..."
            docker start aibianx-billionmail-core > /dev/null 2>&1
            if [ $? -eq 0 ]; then
                echo "âœ… BillionMailå¯åŠ¨æˆåŠŸ"
                echo "   ğŸŒ ç®¡ç†ç•Œé¢: http://localhost:8080"
                return 0
            fi
        fi
    fi
    
    echo "ğŸš€ è‡ªåŠ¨éƒ¨ç½²BillionMail (å®¹å™¨æ¨¡å¼)..."
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç»Ÿä¸€é…ç½®å’ŒDocker Composeæ–‡ä»¶
    if [ -f "deployment/.env" ] && [ -f "deployment/docker-compose.unified.yml" ]; then
        echo "   ğŸ“¦ ä½¿ç”¨ç»Ÿä¸€å®¹å™¨éƒ¨ç½²..."
        cd deployment
        
        # å¯åŠ¨BillionMailç›¸å…³æœåŠ¡
        docker-compose -f docker-compose.unified.yml up -d billionmail-core postfix dovecot rspamd webmail > /dev/null 2>&1
        
        if [ $? -eq 0 ]; then
            echo "âœ… BillionMailéƒ¨ç½²æˆåŠŸ"
            echo "   ğŸŒ ç®¡ç†ç•Œé¢: ${BILLIONMAIL_WEB}"
            echo "   ğŸ“§ WebMail: ${BILLIONMAIL_URL}/webmail"
            echo "   ğŸ” ç®¡ç†å‘˜: admin / (æŸ¥çœ‹deployment/.env)"
        else
            echo "âŒ BillionMailéƒ¨ç½²å¤±è´¥ï¼Œè¯·æ£€æŸ¥DockerçŠ¶æ€"
        fi
        
        cd ..
    else
        echo "âš ï¸  ç»Ÿä¸€é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡BillionMailè‡ªåŠ¨éƒ¨ç½²"
        echo "ğŸ’¡ è¿è¡Œ ./scripts/tools/generate-configs.sh ç”Ÿæˆé…ç½®"
    fi
}

# è°ƒç”¨MeiliSearchéƒ¨ç½²
deploy_meilisearch

# è°ƒç”¨BillionMailéƒ¨ç½² (å¦‚æœå¯ç”¨)
if [ "${AUTO_DEPLOY_BILLIONMAIL:-true}" = "true" ]; then
    deploy_billionmail
fi

# æ£€æŸ¥PostgreSQLæœåŠ¡
check_postgresql() {
    if ! command -v psql &> /dev/null; then
        echo "âš ï¸  PostgreSQL æœªå®‰è£…ï¼Œå°†ä½¿ç”¨SQLiteæ•°æ®åº“"
        return 1
    fi
    
    if ! brew services list | grep -q "postgresql.*started"; then
        echo "ğŸ”„ å¯åŠ¨PostgreSQLæœåŠ¡..."
        brew services start postgresql@14 2>/dev/null || brew services start postgresql 2>/dev/null
        sleep 3
    fi
    
    if psql postgres -c "SELECT 1" > /dev/null 2>&1; then
        echo "âœ… PostgreSQL è¿æ¥æ­£å¸¸"
        return 0
    else
        echo "âš ï¸  PostgreSQL è¿æ¥å¤±è´¥ï¼Œå°†ä½¿ç”¨SQLiteæ•°æ®åº“"
        return 1
    fi
}

# éªŒè¯æ•°æ®åº“è¿æ¥
verify_database() {
    if check_postgresql; then
        echo "ğŸ”„ éªŒè¯æ•°æ®åº“è¿æ¥..."
        
        # æµ‹è¯•è¿æ¥åˆ°æŒ‡å®šæ•°æ®åº“
        if test_postgresql_connection "$DATABASE_NAME"; then
            echo "âœ… æ•°æ®åº“è¿æ¥æ­£å¸¸: $DATABASE_NAME"
            
            # æ˜¾ç¤ºæ•°æ®åº“åŸºæœ¬ä¿¡æ¯
            local info_cmd=$(build_psql_command "$DATABASE_NAME" "-tAc \"SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public'\"")
            local table_count=$(eval "$info_cmd" 2>/dev/null | xargs || echo "0")
            echo "ğŸ“Š æ•°æ®åº“ä¿¡æ¯: å…±æœ‰ $table_count ä¸ªæ•°æ®è¡¨"
        else
            echo "âŒ æ— æ³•è¿æ¥åˆ°æ•°æ®åº“: $DATABASE_NAME"
            echo "ğŸ’¡ è¯·æ£€æŸ¥æ•°æ®åº“é…ç½®æˆ–ä½¿ç”¨ scripts/database/check-database.sh æ£€æŸ¥"
            exit 1
        fi
    else
        # åˆ‡æ¢åˆ°SQLiteé…ç½®
        if [ -f "backend/.env" ]; then
            sed -i '' 's/DATABASE_CLIENT=postgres/DATABASE_CLIENT=sqlite/' backend/.env 2>/dev/null || true
        fi
        echo "âœ… å·²åˆ‡æ¢åˆ°SQLiteæ•°æ®åº“"
    fi
}

echo "ğŸ” éªŒè¯æ•°æ®åº“è¿æ¥..."
verify_database

# æ£€æŸ¥ä¾èµ–å®‰è£…
echo "ğŸ“¦ æ£€æŸ¥ä¾èµ–å®‰è£…..."

if [ ! -d "backend/node_modules" ]; then
    echo "ğŸ”„ å®‰è£…åç«¯ä¾èµ–..."
    cd backend && npm install && cd ..
else
    echo "âœ… åç«¯ä¾èµ–å·²å®‰è£…"
fi

if [ ! -d "frontend/node_modules" ]; then
    echo "ğŸ”„ å®‰è£…å‰ç«¯ä¾èµ–..."
    cd frontend && npm install && cd ..
else
    echo "âœ… å‰ç«¯ä¾èµ–å·²å®‰è£…"
fi

# æ£€æŸ¥ç¯å¢ƒå˜é‡æ–‡ä»¶
if [ ! -f "frontend/.env.local" ] || [ ! -f "backend/.env" ]; then
    echo "âš ï¸  ç¯å¢ƒå˜é‡æ–‡ä»¶ä¸å®Œæ•´ï¼Œæ­£åœ¨è‡ªåŠ¨é…ç½®..."
    source "$(dirname "$0")/../tools/setup-env.sh" || {
        echo "âŒ è‡ªåŠ¨é…ç½®ç¯å¢ƒå˜é‡å¤±è´¥"
        exit 1
    }
else
    echo "âœ… ç¯å¢ƒå˜é‡æ–‡ä»¶å·²å­˜åœ¨"
fi

# ç¯å¢ƒå˜é‡æ–‡ä»¶å·²é€šè¿‡ä¸Šé¢çš„é€»è¾‘å¤„ç†

# æ£€æŸ¥ç«¯å£å ç”¨
check_port() {
    local port=$1
    local service=$2
    if lsof -Pi :$port -sTCP:LISTEN -t >/dev/null; then
        echo "âš ï¸  ç«¯å£ $port å·²è¢«å ç”¨ï¼Œæ­£åœ¨å°è¯•åœæ­¢ $service..."
        pkill -f "$service" 2>/dev/null || true
        sleep 2
        if lsof -Pi :$port -sTCP:LISTEN -t >/dev/null; then
            echo "âŒ æ— æ³•é‡Šæ”¾ç«¯å£ $portï¼Œè¯·æ‰‹åŠ¨åœæ­¢ç›¸å…³è¿›ç¨‹"
            exit 1
        fi
    fi
}

echo "ğŸ” æ£€æŸ¥ç«¯å£å ç”¨..."
check_port 1337 "strapi"
check_port 80 "next"

# æ¸…é™¤ç¼“å­˜
echo "ğŸ§¹ æ¸…é™¤Strapiç¼“å­˜..."
cd backend
if [ -d ".tmp" ] || [ -d ".cache" ] || [ -d "build" ] || [ -d "dist" ]; then
    echo "   ğŸ”„ åˆ é™¤ç¼“å­˜ç›®å½•..."
    rm -rf .tmp .cache build dist 2>/dev/null || true
    echo "   âœ… ç¼“å­˜æ¸…é™¤å®Œæˆ"
else
    echo "   âœ… æ— éœ€æ¸…é™¤ç¼“å­˜ï¼ˆç›®å½•ä¸å­˜åœ¨ï¼‰"
fi

# å¯åŠ¨åç«¯æœåŠ¡
echo "ğŸ”„ å¯åŠ¨Strapiåç«¯æœåŠ¡..."
npm run develop > ../logs/backend.log 2>&1 &
BACKEND_PID=$!
# åˆ›å»ºPIDç›®å½•å¹¶ä¿å­˜PIDæ–‡ä»¶
mkdir -p ../.pids
echo $BACKEND_PID > ../logs/backend.pid
echo $BACKEND_PID > ../.pids/backend.pid
cd ..

echo "âœ… åç«¯æœåŠ¡å·²å¯åŠ¨ (PID: $BACKEND_PID)"
echo "ğŸ“ åç«¯æ—¥å¿—: logs/backend.log"

# ç­‰å¾…åç«¯å¯åŠ¨å®Œæˆ
echo "â³ ç­‰å¾…åç«¯æœåŠ¡å¯åŠ¨å®Œæˆ..."
BACKEND_READY=false
for i in {1..30}; do
    # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ
    if ! kill -0 $BACKEND_PID 2>/dev/null; then
        echo ""
        echo "âŒ åç«¯è¿›ç¨‹å·²é€€å‡ºï¼Œè¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶: logs/backend.log"
        exit 1
    fi
    
    # æ£€æŸ¥åç«¯APIæ˜¯å¦å¯è®¿é—® (ä½¿ç”¨åŠ¨æ€URLè€Œä¸æ˜¯ç¡¬ç¼–ç )
    if curl -s "${BACKEND_API_URL}/articles" > /dev/null 2>&1; then
        echo ""
        echo "âœ… åç«¯æœåŠ¡å¯åŠ¨å®Œæˆ"
        BACKEND_READY=true
        break
    fi
    
    if [ $i -eq 30 ]; then
        echo ""
        echo "âŒ åç«¯æœåŠ¡å¯åŠ¨è¶…æ—¶ï¼ˆ60ç§’ï¼‰ï¼Œè¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶: logs/backend.log"
        echo "ğŸ’¡ å¸¸è§é—®é¢˜ï¼š"
        echo "   - æ•°æ®åº“è¿æ¥é—®é¢˜"
        echo "   - ç«¯å£è¢«å ç”¨"
        echo "   - ç¯å¢ƒå˜é‡é…ç½®é”™è¯¯"
        echo "   - ä¾èµ–åŒ…ç¼ºå¤±"
        kill $BACKEND_PID 2>/dev/null || true
        exit 1
    fi
    sleep 2
    echo -n "."
done

if [ "$BACKEND_READY" != "true" ]; then
    echo "âŒ åç«¯æœåŠ¡å¯åŠ¨å¤±è´¥"
    exit 1
fi

# å¯åŠ¨å‰ç«¯æœåŠ¡
echo "ğŸ”„ å¯åŠ¨Next.jså‰ç«¯æœåŠ¡..."
cd frontend
npm run dev > ../logs/frontend.log 2>&1 &
FRONTEND_PID=$!
# åˆ›å»ºPIDç›®å½•å¹¶ä¿å­˜PIDæ–‡ä»¶
mkdir -p ../.pids
echo $FRONTEND_PID > ../logs/frontend.pid
echo $FRONTEND_PID > ../.pids/frontend.pid
cd ..

echo "âœ… å‰ç«¯æœåŠ¡å·²å¯åŠ¨ (PID: $FRONTEND_PID)"
echo "ğŸ“ å‰ç«¯æ—¥å¿—: logs/frontend.log"

# ç­‰å¾…å‰ç«¯å¯åŠ¨å®Œæˆ
echo "â³ ç­‰å¾…å‰ç«¯æœåŠ¡å¯åŠ¨å®Œæˆ..."
FRONTEND_READY=false
for i in {1..20}; do
    # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ
    if ! kill -0 $FRONTEND_PID 2>/dev/null; then
        echo ""
        echo "âŒ å‰ç«¯è¿›ç¨‹å·²é€€å‡ºï¼Œè¯·æ£€æŸ¥æ—¥å¿—æ–‡ä»¶: logs/frontend.log"
        # æ¸…ç†åç«¯è¿›ç¨‹
        kill $BACKEND_PID 2>/dev/null || true
        exit 1
    fi
    
    # æ£€æŸ¥å‰ç«¯æ˜¯å¦å¯è®¿é—® (ä½¿ç”¨åŠ¨æ€URLè€Œä¸æ˜¯ç¡¬ç¼–ç )
    if curl -s "${FRONTEND_URL}" > /dev/null 2>&1; then
        echo ""
        echo "âœ… å‰ç«¯æœåŠ¡å¯åŠ¨å®Œæˆ"
        FRONTEND_READY=true
        break
    fi
    
    if [ $i -eq 20 ]; then
        echo ""
        echo "âš ï¸  å‰ç«¯æœåŠ¡å¯åŠ¨è¶…æ—¶ï¼ˆ40ç§’ï¼‰ï¼Œä½†è¿›ç¨‹æ­£åœ¨è¿è¡Œ"
        echo "ğŸ’¡ å‰ç«¯æœåŠ¡å¯èƒ½ä»åœ¨ç¼–è¯‘ä¸­ï¼Œè¯·ç¨åè®¿é—®"
        FRONTEND_READY=true  # ç»§ç»­æ‰§è¡Œï¼Œä¸é€€å‡º
        break
    fi
    sleep 2
    echo -n "."
done

echo ""
echo "ğŸ‰ å¼€å‘ç¯å¢ƒå¯åŠ¨å®Œæˆï¼"
echo "========================================="

# è‡ªåŠ¨åŒæ­¥æœç´¢ç´¢å¼•ï¼ˆå¯é€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶ï¼‰
AUTO_SYNC_SEARCH=${AUTO_SYNC_SEARCH:-true}
if [ "$AUTO_SYNC_SEARCH" = "true" ]; then
    echo ""
    echo "ğŸ” è‡ªåŠ¨åŒæ­¥æœç´¢ç´¢å¼•..."
    
    # é™é»˜è¿è¡Œæœç´¢ç´¢å¼•åŒæ­¥
    if [ -f "$(dirname "$0")/../search/quick-reindex.sh" ]; then
        # åˆ›å»ºåå°ä»»åŠ¡åŒæ­¥ç´¢å¼•ï¼Œé¿å…é˜»å¡å¯åŠ¨æµç¨‹
        (
            # ç­‰å¾…MeiliSearchå®Œå…¨å¯åŠ¨ï¼ˆæœ€å¤š60ç§’ï¼‰
            echo "$(date '+%Y-%m-%d %H:%M:%S') - ğŸ” ç­‰å¾…MeiliSearchæœåŠ¡å¯åŠ¨..." >> logs/search-sync.log
            local wait_count=0
            while [ $wait_count -lt 60 ]; do
                if curl -s ${MEILISEARCH_URL}/health > /dev/null 2>&1; then
                    echo "$(date '+%Y-%m-%d %H:%M:%S') - âœ… MeiliSearchæœåŠ¡å·²å°±ç»ª" >> logs/search-sync.log
                    break
                fi
                sleep 1
                wait_count=$((wait_count + 1))
            done
            
            # é¢å¤–ç­‰å¾…5ç§’ç¡®ä¿åç«¯ä¹Ÿå®Œå…¨ç¨³å®š
            sleep 5
            echo "$(date '+%Y-%m-%d %H:%M:%S') - ğŸš€ å¼€å§‹åŒæ­¥æœç´¢ç´¢å¼•..." >> logs/search-sync.log
            
            "$(dirname "$0")/../search/quick-reindex.sh" >> logs/search-sync.log 2>&1
            if [ $? -eq 0 ]; then
                echo "$(date '+%Y-%m-%d %H:%M:%S') - âœ… æœç´¢ç´¢å¼•è‡ªåŠ¨åŒæ­¥å®Œæˆ" >> logs/search-sync.log
            else
                echo "$(date '+%Y-%m-%d %H:%M:%S') - âŒ æœç´¢ç´¢å¼•åŒæ­¥å¤±è´¥" >> logs/search-sync.log
            fi
        ) &
        SEARCH_SYNC_PID=$!
        echo "âœ… æœç´¢ç´¢å¼•åŒæ­¥å·²å¯åŠ¨ (åå°è¿è¡Œï¼ŒPID: $SEARCH_SYNC_PID)"
        echo "ğŸ“ åŒæ­¥æ—¥å¿—: logs/search-sync.log"
        echo "ğŸ” MeiliSearchç®¡ç†: ${MEILISEARCH_URL}"
        
        # ä¿å­˜æœç´¢åŒæ­¥PID
        mkdir -p .pids
        echo $SEARCH_SYNC_PID > .pids/search-sync.pid
    else
        echo "âš ï¸  æœç´¢ç´¢å¼•åŒæ­¥è„šæœ¬ä¸å­˜åœ¨ï¼Œè·³è¿‡è‡ªåŠ¨åŒæ­¥"
    fi
    
    echo "ğŸ’¡ å¯è®¾ç½® AUTO_SYNC_SEARCH=false ç¦ç”¨è‡ªåŠ¨æœç´¢ç´¢å¼•åŒæ­¥"
fi
echo "ğŸ“ è®¿é—®åœ°å€ï¼š"
echo "   ğŸŒ å‰ç«¯ç½‘ç«™: ${FRONTEND_URL}"
echo "   âš™ï¸  åç«¯ç®¡ç†: ${BACKEND_ADMIN_URL}"
echo "   ğŸ“¡ APIæµ‹è¯•: ${BACKEND_API_URL}/articles"
echo "   ğŸ“Š APIæ–‡æ¡£: ${BACKEND_DOCS_URL}"
echo "   ğŸ” æœç´¢å¼•æ“: ${SEARCH_URL}"
echo ""
echo "ğŸ—„ï¸  æ•°æ®åº“çŠ¶æ€ï¼š"
if command -v psql &> /dev/null && test_postgresql_connection; then
    echo "   âœ… PostgreSQL: å·²è¿æ¥ (æ•°æ®åº“: $DATABASE_NAME, ç”¨æˆ·: $DATABASE_USERNAME)"
else
    echo "   âœ… SQLite: å·²å¯ç”¨ (æ–‡ä»¶: backend/.tmp/data.db)"
fi
echo ""
echo "ğŸ“ æ—¥å¿—æ–‡ä»¶ï¼š"
echo "   ğŸ“„ åç«¯æ—¥å¿—: logs/backend.log"
echo "   ğŸ“„ å‰ç«¯æ—¥å¿—: logs/frontend.log"
echo "   ğŸ“„ è¿›ç¨‹ID: .pids/backend.pid, .pids/frontend.pid"
echo ""
echo "ğŸŒ æ‰€æœ‰è®¿é—®åœ°å€ï¼š"
echo "   ğŸ–¥ï¸  å‰ç«¯åº”ç”¨: ${FRONTEND_URL} (AIå˜ç°ä¹‹è·¯ä¸»ç«™)"
echo "   âš™ï¸  åç«¯ç®¡ç†: ${BACKEND_ADMIN_URL} (Strapiç®¡ç†ç•Œé¢)"
echo "   ğŸ“§ é‚®ä»¶è¥é”€: ${BILLIONMAIL_ADMIN_URL} (BillionMailç®¡ç†)"
echo "   ğŸ“¬ WebMail: ${BILLIONMAIL_WEBMAIL_URL} (é‚®ä»¶æ”¶å‘)"
echo "   ğŸ” æœç´¢ç®¡ç†: ${SEARCH_URL} (MeiliSearchç®¡ç†)"
echo "   ğŸ“¡ APIç¤ºä¾‹: ${BACKEND_API_URL}/articles (æ–‡ç« API)"
echo "   ğŸ“Š APIæ–‡æ¡£: ${BACKEND_DOCS_URL} (æ¥å£æ–‡æ¡£)"
echo ""
echo "ğŸ›‘ åœæ­¢æœåŠ¡ï¼š"
echo "   ./stop-dev.sh"
echo ""
echo "ğŸ’¡ æ•…éšœæ’é™¤ï¼š"
echo "   - æŸ¥çœ‹å®æ—¶æ—¥å¿—: tail -f logs/backend.log"
echo "   - æŸ¥çœ‹é”™è¯¯ä¿¡æ¯: tail -n 50 logs/backend.log | grep -i error"
echo "   - æ£€æŸ¥ç«¯å£å ç”¨: lsof -i :1337 æˆ– lsof -i :80"
echo "   - æ£€æŸ¥æ•°æ®åº“è¿æ¥: ./scripts/database/check-database.sh"
echo "   - ç¬¬ä¸€æ¬¡è¿è¡Œå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´è¿›è¡Œç¼–è¯‘"
echo ""
echo "ğŸ”§ æ•°æ®åº“ç®¡ç†ï¼š"
echo "   - è¿æ¥æ•°æ®åº“: $(build_psql_command)"
echo "   - æ•°æ®åº“æ£€æŸ¥: ./scripts/database/check-database.sh"
echo "   - é…ç½®æ–‡ä»¶ä½ç½®: backend/.env" 